{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchview import draw_graph\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    \"\"\"Seeds everything so that experiments are deterministic.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed value.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 30\n",
    "features = 12\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_class = 10\n",
    "num_epoch = 10\n",
    "\n",
    "# classes = ['aimchat', \n",
    "#            'email', \n",
    "#            'facebookChat', \n",
    "#            'ftps',\n",
    "#            'gmailchat', \n",
    "#            'hangoutaudio', \n",
    "#            'icqchat', \n",
    "#            'netflix', \n",
    "#            'scp', \n",
    "#            'sftp', \n",
    "#            'skypevideo', \n",
    "#            'spotify', \n",
    "#            'vimeo', \n",
    "#            'voipbuster', \n",
    "#            'youtube']\n",
    "\n",
    "classes = ('AIM Chat','Email','Facebook Audio','Facebook Chat','Gmail Chat','Hangouts Chat','ICQ Chat','Netflix','Spotify','Youtube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.load('x_train_30K.npy')\n",
    "# y_train = np.load('y_train_30K.npy')\n",
    "# x_test = np.load('x_test_30K.npy')\n",
    "# y_test = np.load('y_test_30K.npy')\n",
    "\n",
    "x_train = np.load(\"x_train-MLP-Multiclass-ISCX-740features.npy\")\n",
    "y_train = np.load(\"y_train-MLP-Multiclass-ISCX-740features.npy\")\n",
    "x_test = np.load(\"x_test-MLP-Multiclass-ISCX-740features.npy\")\n",
    "y_test = np.load(\"y_test-MLP-Multiclass-ISCX-740features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([234964, 360])\n",
      "torch.Size([234964, 360])\n"
     ]
    }
   ],
   "source": [
    "x_train = np.delete(x_train, [12,13,14,15,16,17,18,19], 1)\n",
    "x_test = np.delete(x_test, [12,13,14,15,16,17,18,19], 1)\n",
    "\n",
    "x_train = x_train[:,:sequence*features]\n",
    "x_test = x_test[:,:sequence*features]\n",
    "\n",
    "# x_train = torch.from_numpy(x_train)\n",
    "# y_train = torch.from_numpy(y_train)\n",
    "# x_test = torch.from_numpy(x_test)\n",
    "# y_test = torch.from_numpy(y_test)\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           shuffle=True,\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                           shuffle=False,\n",
    "                                           batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3827"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del train_dataset, test_dataset, x_train, y_train, x_test, y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "NtCNN                                    [64, 30, 12]              [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 30, 12]              [64, 16, 12]              --\n",
       "│    └─Conv1d: 2-1                       [64, 30, 12]              [64, 16, 12]              496\n",
       "│    └─ReLU: 2-2                         [64, 16, 12]              [64, 16, 12]              --\n",
       "├─Sequential: 1-2                        [64, 30, 12]              [64, 32, 12]              --\n",
       "│    └─Conv1d: 2-3                       [64, 30, 12]              [64, 24, 12]              744\n",
       "│    └─Conv1d: 2-4                       [64, 24, 12]              [64, 32, 12]              2,336\n",
       "│    └─ReLU: 2-5                         [64, 32, 12]              [64, 32, 12]              --\n",
       "├─Sequential: 1-3                        [64, 30, 12]              [64, 16, 12]              --\n",
       "│    └─Conv1d: 2-6                       [64, 30, 12]              [64, 8, 12]               248\n",
       "│    └─Conv1d: 2-7                       [64, 8, 12]               [64, 16, 12]              656\n",
       "│    └─ReLU: 2-8                         [64, 16, 12]              [64, 16, 12]              --\n",
       "├─Sequential: 1-4                        [64, 30, 12]              [64, 16, 12]              --\n",
       "│    └─MaxPool1d: 2-9                    [64, 30, 12]              [64, 30, 12]              --\n",
       "│    └─Conv1d: 2-10                      [64, 30, 12]              [64, 16, 12]              496\n",
       "│    └─ReLU: 2-11                        [64, 16, 12]              [64, 16, 12]              --\n",
       "├─Linear: 1-5                            [64, 960]                 [64, 128]                 123,008\n",
       "├─ReLU: 1-6                              [64, 128]                 [64, 128]                 --\n",
       "├─Linear: 1-7                            [64, 128]                 [64, 64]                  8,256\n",
       "├─ReLU: 1-8                              [64, 64]                  [64, 64]                  --\n",
       "├─Linear: 1-9                            [64, 64]                  [64, 10]                  650\n",
       "===================================================================================================================\n",
       "Total params: 136,890\n",
       "Trainable params: 136,890\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 12.26\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.09\n",
       "Forward/backward pass size (MB): 0.79\n",
       "Params size (MB): 0.55\n",
       "Estimated Total Size (MB): 1.43\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NtCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NtCNN, self).__init__()\n",
    "\n",
    "        # 1x1 convolution branch\n",
    "        self.branch1x1 = nn.Sequential(\n",
    "            nn.Conv1d(sequence, 16, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 1x1 convolution followed by 3x3 convolution branch\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            nn.Conv1d(sequence, 24, kernel_size=1),  # Reduce channels from 36 to 24\n",
    "            nn.Conv1d(24, 32, kernel_size=3, padding=1)  # 3x3 convolution \n",
    "            ,nn.ReLU()\n",
    "            #,nn.GELU()    \n",
    "        )\n",
    "\n",
    "        # 1x1 convolution followed by 5x5 convolution branch\n",
    "        self.branch5x5 = nn.Sequential(\n",
    "            nn.Conv1d(sequence, 8, kernel_size=1),  # Reduce channels from 36 to 8\n",
    "            nn.Conv1d(8, 16, kernel_size=5, padding=2)  # 5x5\n",
    "            ,nn.ReLU()\n",
    "            #,nn.GELU()            \n",
    "        )\n",
    "\n",
    "        # 3x3 max pooling followed by 1x1 convolution branch\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv1d(sequence, 16, kernel_size=1)  # Reduce channels to 16\n",
    "            ,nn.ReLU()\n",
    "            #,nn.GELU()  \n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(80*12, 128)\n",
    "        self.activation5 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.activation6 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(64,num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1, sequence, features)\n",
    "        \n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "        branch5x5 = self.branch5x5(x)\n",
    "        branch_pool = self.branch_pool(x)\n",
    "        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n",
    "        x = torch.cat(outputs, 1)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 80*12)\n",
    "        # #print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation5(x)\n",
    "        # #print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation6(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        # #print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = NtCNN().to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model, \n",
    "        input_size=[batch_size, sequence, features], \n",
    "        device=device, \n",
    "        col_names=[\"input_size\",\"output_size\", \"num_params\"])\n",
    "\n",
    "# architecture = 'InceptionBlock'\n",
    "# model_graph = draw_graph(model, input_size=(batch_size, features, timestep), graph_dir ='TB' , roll=True, expand_nested=True, graph_name=f'self_{architecture}',save_graph=True,filename=f'self_{architecture}')\n",
    "# model_graph.visual_graph\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "178.99322902329732 80.51555729965912\n",
    "Epoch : 1/10, Loss: 0.0487, Validation Loss: 0.0512\n",
    "100%\n",
    " 3672/3672 [00:26<00:00, 155.65it/s]\n",
    "166.9994734448701 75.575640315481\n",
    "Epoch : 2/10, Loss: 0.0455, Validation Loss: 0.0480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31c3d66086a4223b3e188e12d23de8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3047.541883856058 822.7246540486813\n",
      "Epoch : 1/10, Loss: 0.8299, Validation Loss: 0.5227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5a6825de9540ef9469ed9681956d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591.1087301820517 576.6133679077029\n",
      "Epoch : 2/10, Loss: 0.4333, Validation Loss: 0.3663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d1f14a2abc4b5f81c479a55b985324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1175.0092224106193 424.4206230863929\n",
      "Epoch : 3/10, Loss: 0.3200, Validation Loss: 0.2696\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf064d37e044c37987a634ad54d8a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877.8807469755411 323.73111552372575\n",
      "Epoch : 4/10, Loss: 0.2391, Validation Loss: 0.2057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2372c0b0e2664b09b7fb99c1154ca694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683.5549684930593 255.0971992854029\n",
      "Epoch : 5/10, Loss: 0.1862, Validation Loss: 0.1621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26235ed68cbd4f56b65b11d708516a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574.1922455085441 218.23457168322057\n",
      "Epoch : 6/10, Loss: 0.1564, Validation Loss: 0.1386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3023fcd5c0fe43cf8afe5a50f5c90e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485.75082339253277 189.72116636112332\n",
      "Epoch : 7/10, Loss: 0.1323, Validation Loss: 0.1205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4a534b53d84a4298e6d8b737661eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411.9713514104951 183.1888794163242\n",
      "Epoch : 8/10, Loss: 0.1122, Validation Loss: 0.1164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818dce1b1e784eca89e43e15f6f764ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346.82905289984774 145.1801425931044\n",
      "Epoch : 9/10, Loss: 0.0945, Validation Loss: 0.0922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68a989f736d4989ae5f8388acdafc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301.4989258693531 135.1786576739978\n",
      "Epoch : 10/10, Loss: 0.0821, Validation Loss: 0.0859\n",
      "Time Taken: 321.393274307251\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# import wandb\n",
    "\n",
    "# wandb.init(project=\"torch-CNN\",\n",
    "#            #mode='offline',\n",
    "#            config = {\"learning_rate\": learning_rate, \"epochs\": num_epoch, \"batch_size\": batch_size})\n",
    "\n",
    "# wandb.watch(model, criterion=criterion, log='all', log_freq=100)\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epoch):\n",
    "    avgloss = 0\n",
    "    for i, (sample, labels) in enumerate(tqdm(train_loader)):\n",
    "        model.train()\n",
    "        sample = sample.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        predictions = model(sample)\n",
    "        \n",
    "        loss = criterion(predictions,labels)\n",
    "\n",
    "        avgloss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        \n",
    "    avg_val_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for samples, labels in test_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(samples)\n",
    "            #labels = torch.argmax(labels, dim=1)\n",
    "            \n",
    "            val_loss = criterion(predictions, labels)\n",
    "\n",
    "            avg_val_loss += val_loss.item()\n",
    "\n",
    "    \n",
    "    avgloss /= len(train_loader)\n",
    "    avg_val_loss /= len(test_loader)\n",
    "    print(f'Epoch : {epoch+1}/{num_epoch}, Loss: {avgloss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "    # wandb.log({\"epoch\": (epoch+1), \"loss\": avgloss, \"Validation Loss\": avg_val_loss})\n",
    "end = time.time()\n",
    "\n",
    "print(f'Time Taken:', (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Taken: 290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      AIM Chat     0.7739    0.5272    0.6272       753\n",
      "         Email     0.9577    0.9558    0.9568      7176\n",
      "Facebook Audio     0.9968    0.9953    0.9960     41110\n",
      " Facebook Chat     0.8812    0.8651    0.8731      2453\n",
      "    Gmail Chat     0.8205    0.8743    0.8466      3676\n",
      " Hangouts Chat     0.9398    0.9023    0.9207      2958\n",
      "      ICQ Chat     0.5788    0.8311    0.6824       663\n",
      "       Netflix     0.9955    0.9969    0.9962     31187\n",
      "       Spotify     0.9746    0.9584    0.9664      4521\n",
      "       Youtube     0.9859    0.9827    0.9843      6202\n",
      "\n",
      "      accuracy                         0.9756    100699\n",
      "     macro avg     0.8905    0.8889    0.8850    100699\n",
      "  weighted avg     0.9766    0.9756    0.9757    100699\n",
      "\n",
      "[[  397    15     1    28    90     8   211     1     0     2]\n",
      " [    9  6859    12    26   243     9    16     0     0     2]\n",
      " [    0    35 40915    34     8     0     4    41    31    42]\n",
      " [   17    16    24  2122   200    16    46     1     8     3]\n",
      " [   43   166     2    65  3214   125    60     0     0     1]\n",
      " [   13    15     3    91   104  2669    59     0     1     3]\n",
      " [   33    10     0    24    29     8   551     2     3     3]\n",
      " [    1     4    24     3     4     1     0 31091    48    11]\n",
      " [    0    13    39     9    15     2     1    89  4333    20]\n",
      " [    0    29    26     6    10     2     4     8    22  6095]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib as plt\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "  # Disable gradient computation for testing\n",
    "with torch.inference_mode():    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device).float()  # Move images to the appropriate device\n",
    "        labels = labels.to(device).float()  # Move labels to the appropriate device\n",
    "\n",
    "        predictions = model(images)  # Get predictions from the model\n",
    "\n",
    "        # Convert model output (predictions) to class indices\n",
    "        preds = torch.argmax(predictions, dim=1)\n",
    "        \n",
    "        # Convert one-hot encoded labels to class indices\n",
    "        labels = torch.argmax(labels, dim=1) # add this line for one hot encoded labels\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        all_preds.extend(preds.cpu().numpy())  # Move to CPU and convert to numpy\n",
    "        all_labels.extend(labels.cpu().numpy())  # Move to CPU and convert to numpy\n",
    "\n",
    "# Generate and print the confusion matrix and classification report\n",
    "print(classification_report(all_labels, all_preds, target_names=classes, digits=4))\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(all_labels, all_preds), display_labels=list(range(15)))\n",
    "#disp.plot(cmap=plt.cm.Blues)\n",
    "# wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envjetson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
